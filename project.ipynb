{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDELa7o5UXrY"
      },
      "source": [
        "# DX 704 Week 1 Project\n",
        "\n",
        "This week's project will build a portfolio risk and return model, and make investing recommendations for hypothetical clients.\n",
        "You will collect historical data, estimate returns and risks, construct efficient frontier portfolios, and sanity check the certainty of the maximum return portfolio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6SxppNu8p8k"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub at the following link.\n",
        "\n",
        "https://github.com/bu-cds-dx704/dx704-project-01\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmIaQcdCwObV"
      },
      "source": [
        "Feel free to use optimization tools or libraries (such as CVXOPT or scipy.optimize) to perform any calculations required for this mini project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv3PslO0V5Lm"
      },
      "source": [
        "## Part 1: Collect Data\n",
        "\n",
        "Collect historical monthly price data for the last 24 months covering 6 different stocks.\n",
        "The data should cover 24 consecutive months including the last month that ended before this week's material was released on Blackboard.\n",
        "To be clear, if a month ends between the Blackboard release and submitting your project, you do not need to add that month.\n",
        "\n",
        "The six different stocks must include AAPL, SPY and TSLA.\n",
        "At least one of the remaining 3 tickers must start with the same letter as your last name (e.g. professor Considine could use COIN).\n",
        "This is to encourage diversity in what stocks you analyze; if you discuss this project with classmates, please make sure that you pick different tickers to differentiate your work.\n",
        "Do not pick stocks with fewer than 24 consecutive months of price data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.optimize import minimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6pL-ppubxfvC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "Tickers: ['AAPL', 'SPY', 'TSLA', 'MSFT', 'M', 'MCD']\n",
            "Date range: 9/2023 to 8/2025\n",
            "Expected months: 24\n",
            "Functions completed\n"
          ]
        }
      ],
      "source": [
        "# Tickers - must include AAPL, SPY, TSLA\n",
        "# The last 3 chosen start with M (for Mufti :D )\n",
        "ALL_TICKERS = [\n",
        "    'AAPL',  # Apple (required)\n",
        "    'SPY',   # S&P 500 (required)\n",
        "    'TSLA',  # Tesla (required)\n",
        "    'MSFT',  # Microsoft\n",
        "    'M',     # Macy's\n",
        "    'MCD'    # McDonald's\n",
        "]\n",
        "\n",
        "# Date range: 24 consecutive months ending August 2025\n",
        "START_MONTH = 9   # September\n",
        "START_YEAR = 2023\n",
        "END_MONTH = 8     # August\n",
        "END_YEAR = 2025\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"Tickers: {ALL_TICKERS}\")\n",
        "print(f\"Date range: {START_MONTH}/{START_YEAR} to {END_MONTH}/{END_YEAR}\")\n",
        "print(f\"Expected months: {(END_YEAR - START_YEAR) * 12 + (END_MONTH - START_MONTH) + 1}\")\n",
        "\n",
        "# Data collection functions\n",
        "# Generates a list of end-month dates for the defined set range\n",
        "def get_end_month_dates(start_year, start_month, end_year, end_month):\n",
        "    dates = []\n",
        "    current_year, current_month = start_year, start_month\n",
        "    \n",
        "    while (current_year, current_month) <= (end_year, end_month):\n",
        "        # Get last day of month\n",
        "        last_day = calendar.monthrange(current_year, current_month)[1]\n",
        "        date = datetime(current_year, current_month, last_day)\n",
        "        dates.append(date)\n",
        "        \n",
        "        # Move to next month\n",
        "        current_month += 1\n",
        "        if current_month > 12:\n",
        "            current_month = 1\n",
        "            current_year += 1\n",
        "    \n",
        "    return dates\n",
        "\n",
        "# Gets the stock price data for the defined target dates\n",
        "def get_stock_data_for_dates(ticker, target_dates):\n",
        "    print(f\"Getting data for {ticker}\")\n",
        "    \n",
        "    # Download data with buffer around our date range\n",
        "    start_date = target_dates[0].replace(day=1)  # Start of first month\n",
        "    end_date = target_dates[-1]\n",
        "    \n",
        "    try:\n",
        "        # Download stock data - explicitly set auto_adjust to avoid warning\n",
        "        stock_data = yf.download(ticker, start=start_date, end=end_date, \n",
        "                               progress=False, auto_adjust=False)\n",
        "        \n",
        "        if stock_data.empty:\n",
        "            print(f\"PROBLEM: No data returned for {ticker}\")\n",
        "            return [None] * len(target_dates), [None] * len(target_dates)\n",
        "        \n",
        "        # Debug: print column names to see what we got\n",
        "        print(f\"  Columns for {ticker}: {list(stock_data.columns)}\")\n",
        "        \n",
        "        prices = []\n",
        "        actual_dates = []\n",
        "        \n",
        "        # Find the last available trading day of the month\n",
        "        for target_date in target_dates:\n",
        "            found_price = None\n",
        "            found_date = None\n",
        "            \n",
        "            # Look back up to 5 days for trading day\n",
        "            for days_back in range(5):  \n",
        "                check_date = target_date - pd.Timedelta(days=days_back)\n",
        "                \n",
        "                if check_date.date() in [d.date() for d in stock_data.index]:\n",
        "                    # Once a trading day is found\n",
        "                    trading_day = [d for d in stock_data.index if d.date() == check_date.date()][0]\n",
        "                    \n",
        "                    # Try different possible column names for adjusted close\n",
        "                    adj_close_value = None\n",
        "                    if 'Adj Close' in stock_data.columns:\n",
        "                        adj_close_value = stock_data.loc[trading_day, 'Adj Close']\n",
        "                    elif ('Adj Close', ticker) in stock_data.columns:\n",
        "                        adj_close_value = stock_data.loc[trading_day, ('Adj Close', ticker)]\n",
        "                    elif len(stock_data.columns) == 6:  # Standard OHLCV + Adj Close\n",
        "                        adj_close_value = stock_data.iloc[stock_data.index.get_loc(trading_day), 5]  # Usually last column\n",
        "                    else:\n",
        "                        # Fall back to regular Close if Adj Close not available\n",
        "                        if 'Close' in stock_data.columns:\n",
        "                            adj_close_value = stock_data.loc[trading_day, 'Close']\n",
        "                        elif ('Close', ticker) in stock_data.columns:\n",
        "                            adj_close_value = stock_data.loc[trading_day, ('Close', ticker)]\n",
        "                    \n",
        "                    if adj_close_value is not None:\n",
        "                        found_price = round(float(adj_close_value), 2)\n",
        "                        found_date = trading_day.strftime('%Y-%m-%d')\n",
        "                        break\n",
        "            \n",
        "            if found_price is None:\n",
        "                print(f\"PROBLEM: No trading data found for {ticker} around {target_date.strftime('%Y-%m-%d')}\")\n",
        "            \n",
        "            prices.append(found_price)\n",
        "            actual_dates.append(found_date)\n",
        "\n",
        "        return prices, actual_dates\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"ERROR getting data for {ticker}: {e}\")\n",
        "        print(f\"  Exception type: {type(e)}\")\n",
        "        return [None] * len(target_dates), [None] * len(target_dates)\n",
        "\n",
        "print(\"Functions completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uH9oDQ1rEQT"
      },
      "source": [
        "Save the data as a TSV file named \"historical_prices.tsv\" and include a header row with the column names \"date\" and the 6 stock ticker symbols.\n",
        "The date should be the last trading day of the month, so it may not be the last day of the month.\n",
        "For example, the last trading day of November 2024 was 2024-11-29.\n",
        "The remaining columns should contain the adjusted closing prices of the corresponding stock tickers on that day.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mHbwKHOhtQ3E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Data Collector\n",
            "==================================================\n",
            "\n",
            "Target dates generated: 24 months\n",
            "First date: 2023-09-30\n",
            "Last date: 2025-08-31\n",
            "\n",
            "--------------------------------------------------\n",
            "Getting data for AAPL\n",
            "  Columns for AAPL: [('Adj Close', 'AAPL'), ('Close', 'AAPL'), ('High', 'AAPL'), ('Low', 'AAPL'), ('Open', 'AAPL'), ('Volume', 'AAPL')]\n",
            "Getting data for SPY\n",
            "  Columns for SPY: [('Adj Close', 'SPY'), ('Close', 'SPY'), ('High', 'SPY'), ('Low', 'SPY'), ('Open', 'SPY'), ('Volume', 'SPY')]\n",
            "Getting data for TSLA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2148/2996265075.py:95: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  found_price = round(float(adj_close_value), 2)\n",
            "/tmp/ipykernel_2148/2996265075.py:95: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  found_price = round(float(adj_close_value), 2)\n",
            "/tmp/ipykernel_2148/2996265075.py:95: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  found_price = round(float(adj_close_value), 2)\n",
            "/tmp/ipykernel_2148/2996265075.py:95: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  found_price = round(float(adj_close_value), 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Columns for TSLA: [('Adj Close', 'TSLA'), ('Close', 'TSLA'), ('High', 'TSLA'), ('Low', 'TSLA'), ('Open', 'TSLA'), ('Volume', 'TSLA')]\n",
            "Getting data for MSFT\n",
            "  Columns for MSFT: [('Adj Close', 'MSFT'), ('Close', 'MSFT'), ('High', 'MSFT'), ('Low', 'MSFT'), ('Open', 'MSFT'), ('Volume', 'MSFT')]\n",
            "Getting data for M\n",
            "  Columns for M: [('Adj Close', 'M'), ('Close', 'M'), ('High', 'M'), ('Low', 'M'), ('Open', 'M'), ('Volume', 'M')]\n",
            "Getting data for MCD\n",
            "  Columns for MCD: [('Adj Close', 'MCD'), ('Close', 'MCD'), ('High', 'MCD'), ('Low', 'MCD'), ('Open', 'MCD'), ('Volume', 'MCD')]\n",
            "\n",
            "==================================================\n",
            "\n",
            "Collected Data Preview:\n",
            "First 5 rows:\n",
            "         date    AAPL     SPY    TSLA    MSFT      M     MCD\n",
            "0  2023-09-29  169.55  417.87  250.22  311.06  10.74  251.35\n",
            "1  2023-10-31  169.11  408.79  200.84  333.09  11.27  250.13\n",
            "2  2023-11-30  188.36  446.14  240.08  374.04  14.68  270.51\n",
            "3  2023-12-29  190.91  466.50  248.48  371.21  18.78  284.59\n",
            "4  2024-01-31  182.85  473.93  187.29  392.47  17.07  280.96\n",
            "\n",
            "Last 5 rows:\n",
            "          date    AAPL     SPY    TSLA    MSFT      M     MCD\n",
            "19  2025-04-30  211.98  552.91  282.16  393.89  11.25  316.05\n",
            "20  2025-05-30  200.62  587.65  346.46  459.60  11.71  310.32\n",
            "21  2025-06-30  204.94  617.85  317.66  496.59  11.66  290.52\n",
            "22  2025-07-31  207.33  632.08  308.27  532.62  12.63  298.38\n",
            "23  2025-08-29  232.14  645.05  333.87  506.69  13.23  311.77\n",
            "\n",
            "Data saved to: historical_prices.tsv\n",
            "\n",
            "Data Quality Summary:\n",
            "Total months collected: 24\n",
            "  AAPL: 24/24 valid prices (100.0%)\n",
            "  SPY: 24/24 valid prices (100.0%)\n",
            "  TSLA: 24/24 valid prices (100.0%)\n",
            "  MSFT: 24/24 valid prices (100.0%)\n",
            "  M: 24/24 valid prices (100.0%)\n",
            "  MCD: 24/24 valid prices (100.0%)\n",
            "\n",
            "File verification: historical_prices.tsv created successfully (1269 bytes)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2148/2996265075.py:95: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  found_price = round(float(adj_close_value), 2)\n",
            "/tmp/ipykernel_2148/2996265075.py:95: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  found_price = round(float(adj_close_value), 2)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Using our functions we made lets get our stock data and save it to a dataframe with the specified format\n",
        "print(\"Stock Data Collector\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Get target dates (month ends)\n",
        "target_dates = get_end_month_dates(START_YEAR, START_MONTH, END_YEAR, END_MONTH)\n",
        "print(f\"\\nTarget dates generated: {len(target_dates)} months\")\n",
        "print(f\"First date: {target_dates[0].strftime('%Y-%m-%d')}\")\n",
        "print(f\"Last date: {target_dates[-1].strftime('%Y-%m-%d')}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {}\n",
        "\n",
        "# Collect data for each ticker\n",
        "for ticker in ALL_TICKERS:\n",
        "    prices, dates = get_stock_data_for_dates(ticker, target_dates)\n",
        "    results[ticker] = prices\n",
        "    \n",
        "    # Use dates from first successful ticker for the date column\n",
        "    if 'date' not in results and dates[0] is not None:\n",
        "        results['date'] = dates\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Reorder columns to have date first\n",
        "columns = ['date'] + ALL_TICKERS\n",
        "df = df[columns]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "# Display results preview\n",
        "print(\"\\nCollected Data Preview:\")\n",
        "print(\"First 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nLast 5 rows:\")\n",
        "print(df.tail())\n",
        "\n",
        "# Save to TSV file\n",
        "output_file = \"historical_prices.tsv\"\n",
        "df.to_csv(output_file, sep='\\t', index=False)\n",
        "print(f\"\\nData saved to: {output_file}\")\n",
        "\n",
        "# Data quality check\n",
        "print(f\"\\nData Quality Summary:\")\n",
        "print(f\"Total months collected: {len(df)}\")\n",
        "for ticker in ALL_TICKERS:\n",
        "    valid_count = df[ticker].notna().sum()\n",
        "    percentage = (valid_count/len(df)*100) if len(df) > 0 else 0\n",
        "    print(f\"  {ticker}: {valid_count}/{len(df)} valid prices ({percentage:.1f}%)\")\n",
        "\n",
        "# Verify file creation\n",
        "if os.path.exists(output_file):\n",
        "    file_size = os.path.getsize(output_file)\n",
        "    print(f\"\\nFile verification: {output_file} created successfully ({file_size} bytes)\")\n",
        "else:\n",
        "    print(f\"\\nERROR: {output_file} was not created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hp0yuXPtT9V"
      },
      "source": [
        "Submit \"historical_prices.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XdNVWWirUd5"
      },
      "source": [
        "## Part 2: Calculate Historical Asset Returns\n",
        "\n",
        "Calculate the historical asset returns based on the price data that you previously collected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aL-kVua2xex-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Price data loaded:\n",
            "Shape: (24, 7)\n",
            "First few rows:\n",
            "         date    AAPL     SPY    TSLA    MSFT      M     MCD\n",
            "0  2023-09-29  169.55  417.87  250.22  311.06  10.74  251.35\n",
            "1  2023-10-31  169.11  408.79  200.84  333.09  11.27  250.13\n",
            "2  2023-11-30  188.36  446.14  240.08  374.04  14.68  270.51\n",
            "3  2023-12-29  190.91  466.50  248.48  371.21  18.78  284.59\n",
            "4  2024-01-31  182.85  473.93  187.29  392.47  17.07  280.96\n",
            "\n",
            "Calculating returns for: ['AAPL', 'SPY', 'TSLA', 'MSFT', 'M', 'MCD']\n",
            "\n",
            "Returns calculated:\n",
            "Shape: (23, 7)\n",
            "First few rows:\n",
            "         date      AAPL       SPY      TSLA      MSFT         M       MCD\n",
            "0  2023-10-31 -0.002595 -0.021729 -0.197346  0.070822  0.049348 -0.004854\n",
            "1  2023-11-30  0.113831  0.091367  0.195379  0.122940  0.302573  0.081478\n",
            "2  2023-12-29  0.013538  0.045636  0.034988 -0.007566  0.279292  0.052050\n",
            "3  2024-01-31 -0.042219  0.015927 -0.246257  0.057272 -0.091054 -0.012755\n",
            "4  2024-02-29 -0.018540  0.052202  0.077901  0.042322 -0.046280  0.004164\n",
            "\n",
            "Last few rows:\n",
            "          date      AAPL       SPY      TSLA      MSFT         M       MCD\n",
            "18  2025-04-30 -0.043368 -0.008660  0.088748  0.052928 -0.090542  0.023312\n",
            "19  2025-05-30 -0.053590  0.062831  0.227885  0.166823  0.040889 -0.018130\n",
            "20  2025-06-30  0.021533  0.051391 -0.083126  0.080483 -0.004270 -0.063805\n",
            "21  2025-07-31  0.011662  0.023031 -0.029560  0.072555  0.083190  0.027055\n",
            "22  2025-08-29  0.119664  0.020520  0.083044 -0.048684  0.047506  0.044876\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "# Read the price data we created in Part 1\n",
        "price_data = pd.read_csv(\"historical_prices.tsv\", sep='\\t')\n",
        "\n",
        "print(\"Price data loaded:\")\n",
        "print(f\"Shape: {price_data.shape}\")\n",
        "print(\"First few rows:\")\n",
        "print(price_data.head())\n",
        "\n",
        "# Get all ticker columns (exclude the date column)\n",
        "tickers = [col for col in price_data.columns if col != 'date']\n",
        "print(f\"\\nCalculating returns for: {tickers}\")\n",
        "\n",
        "# Use pandas pct_change() method to calculate returns\n",
        "# This calculates (current - previous) / previous automatically\n",
        "# From lecture we want (ending price - starting price)/ starting price\n",
        "price_returns = price_data[tickers].pct_change()\n",
        "\n",
        "# Drop the first row since it will be NaN (no previous price)\n",
        "price_returns = price_returns.iloc[1:]\n",
        "\n",
        "# Add the dates (also drop first date to match)\n",
        "dates = price_data['date'].iloc[1:].reset_index(drop=True)\n",
        "\n",
        "# Create returns DataFrame\n",
        "returns_df = pd.DataFrame()\n",
        "returns_df['date'] = dates\n",
        "\n",
        "# Add the ticker returns\n",
        "for ticker in tickers:\n",
        "    returns_df[ticker] = price_returns[ticker].reset_index(drop=True).round(6)\n",
        "\n",
        "print(f\"\\nReturns calculated:\")\n",
        "print(f\"Shape: {returns_df.shape}\")\n",
        "print(\"First few rows:\")\n",
        "print(returns_df.head())\n",
        "print(\"\\nLast few rows:\")\n",
        "print(returns_df.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjhEYCWOrIu3"
      },
      "source": [
        "Save the data as a TSV file named \"historical_returns.tsv\" and include a header row with the column names \"date\" and the 6 stock ticker symbols.\n",
        "Each row should have the date at the end of the month and the corresponding *relative* price changes.\n",
        "For example, if the previous price was \\$100 and the new price is \\$110, the return value should be 0.10.\n",
        "There should only be 23 rows of data in this file, since they are computed as the differences of 24 prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "cN-7q9QvvyKG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Returns data saved to: historical_returns.tsv\n",
            "\n",
            "Summary:\n",
            "Total return periods: 23 (should be 23)\n",
            "Date range: 2023-10-31 to 2025-08-29\n",
            "\n",
            "Sample return calculations:\n",
            "\n",
            "Month 1 (2023-10-31):\n",
            "  AAPL: $169.55 -> $169.11 = -0.0026\n",
            "  SPY: $417.87 -> $408.79 = -0.0217\n",
            "  TSLA: $250.22 -> $200.84 = -0.1973\n",
            "  MSFT: $311.06 -> $333.09 = 0.0708\n",
            "  M: $10.74 -> $11.27 = 0.0493\n",
            "  MCD: $251.35 -> $250.13 = -0.0049\n",
            "\n",
            "Month 2 (2023-11-30):\n",
            "  AAPL: $169.11 -> $188.36 = 0.1138\n",
            "  SPY: $408.79 -> $446.14 = 0.0914\n",
            "  TSLA: $200.84 -> $240.08 = 0.1954\n",
            "  MSFT: $333.09 -> $374.04 = 0.1229\n",
            "  M: $11.27 -> $14.68 = 0.3026\n",
            "  MCD: $250.13 -> $270.51 = 0.0815\n",
            "\n",
            "Month 3 (2023-12-29):\n",
            "  AAPL: $188.36 -> $190.91 = 0.0135\n",
            "  SPY: $446.14 -> $466.50 = 0.0456\n",
            "  TSLA: $240.08 -> $248.48 = 0.0350\n",
            "  MSFT: $374.04 -> $371.21 = -0.0076\n",
            "  M: $14.68 -> $18.78 = 0.2793\n",
            "  MCD: $270.51 -> $284.59 = 0.0520\n",
            "\n",
            "Data Quality Summary:\n",
            "  AAPL: 23/23 valid returns (100.0%)\n",
            "  SPY: 23/23 valid returns (100.0%)\n",
            "  TSLA: 23/23 valid returns (100.0%)\n",
            "  MSFT: 23/23 valid returns (100.0%)\n",
            "  M: 23/23 valid returns (100.0%)\n",
            "  MCD: 23/23 valid returns (100.0%)\n",
            "\n",
            "File verification: historical_returns.tsv created successfully (1566 bytes)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Save to TSV file\n",
        "output_file = \"historical_returns.tsv\"\n",
        "returns_df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "print(f\"Returns data saved to: {output_file}\")\n",
        "\n",
        "# Verify the file and show summary\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"Total return periods: {len(returns_df)} (should be 23)\")\n",
        "print(f\"Date range: {returns_df.iloc[0]['date']} to {returns_df.iloc[-1]['date']}\")\n",
        "\n",
        "# Show sample calculations for verification\n",
        "print(f\"\\nSample return calculations:\")\n",
        "for i in range(min(3, len(returns_df))):\n",
        "    print(f\"\\nMonth {i+1} ({returns_df.iloc[i]['date']}):\")\n",
        "    for ticker in tickers:\n",
        "        if i < len(price_data) - 1:\n",
        "            prev_price = price_data.iloc[i][ticker]\n",
        "            curr_price = price_data.iloc[i+1][ticker] \n",
        "            calculated_return = returns_df.iloc[i][ticker]\n",
        "            print(f\"  {ticker}: ${prev_price:.2f} -> ${curr_price:.2f} = {calculated_return:.4f}\")\n",
        "\n",
        "# Data quality check (checking calculation work here)\n",
        "print(f\"\\nData Quality Summary:\")\n",
        "for ticker in tickers:\n",
        "    valid_count = returns_df[ticker].notna().sum()\n",
        "    percentage = (valid_count/len(returns_df)*100) if len(returns_df) > 0 else 0\n",
        "    print(f\"  {ticker}: {valid_count}/{len(returns_df)} valid returns ({percentage:.1f}%)\")\n",
        "\n",
        "# File verification\n",
        "if os.path.exists(output_file):\n",
        "    file_size = os.path.getsize(output_file)\n",
        "    print(f\"\\nFile verification: {output_file} created successfully ({file_size} bytes)\")\n",
        "else:\n",
        "    print(f\"\\nERROR: {output_file} was not created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyBtnCTUtfRq"
      },
      "source": [
        "Submit \"historical_returns.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoCkf4ouV9IA"
      },
      "source": [
        "## Part 3: Estimate Returns\n",
        "\n",
        "Estimate the expected returns for each asset using the previously calculated return data.\n",
        "Just compute the average (mean) return for each asset over your data set; do not use other estimators that have been mentioned.\n",
        "This will serve as your estimate of expected return for each asset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "N2iDEhSRxd2n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Returns data loaded:\n",
            "Shape: (23, 7)\n",
            "First few rows:\n",
            "         date      AAPL       SPY      TSLA      MSFT         M       MCD\n",
            "0  2023-10-31 -0.002595 -0.021729 -0.197346  0.070822  0.049348 -0.004854\n",
            "1  2023-11-30  0.113831  0.091367  0.195379  0.122940  0.302573  0.081478\n",
            "2  2023-12-29  0.013538  0.045636  0.034988 -0.007566  0.279292  0.052050\n",
            "3  2024-01-31 -0.042219  0.015927 -0.246257  0.057272 -0.091054 -0.012755\n",
            "4  2024-02-29 -0.018540  0.052202  0.077901  0.042322 -0.046280  0.004164\n",
            "\n",
            "Calculating expected returns for: ['AAPL', 'SPY', 'TSLA', 'MSFT', 'M', 'MCD']\n",
            "AAPL: 0.015442 (1.5442% per month)\n",
            "SPY: 0.019666 (1.9666% per month)\n",
            "TSLA: 0.025313 (2.5313% per month)\n",
            "MSFT: 0.023318 (2.3318% per month)\n",
            "M: 0.014757 (1.4757% per month)\n",
            "MCD: 0.010268 (1.0268% per month)\n",
            "\n",
            "Estimated returns calculated for 6 assets\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Read the returns data we created in Part 2\n",
        "returns_data = pd.read_csv(\"historical_returns.tsv\", sep='\\t')\n",
        "\n",
        "print(\"Returns data loaded:\")\n",
        "print(f\"Shape: {returns_data.shape}\")\n",
        "print(\"First few rows:\")\n",
        "print(returns_data.head())\n",
        "\n",
        "# Get all ticker columns (exclude the date column)\n",
        "tickers = [col for col in returns_data.columns if col != 'date']\n",
        "print(f\"\\nCalculating expected returns for: {tickers}\")\n",
        "\n",
        "# Calculate the mean return for each asset\n",
        "estimated_returns = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    mean_return = returns_data[ticker].mean()\n",
        "    estimated_returns[ticker] = mean_return\n",
        "    print(f\"{ticker}: {mean_return:.6f} ({mean_return*100:.4f}% per month)\")\n",
        "\n",
        "print(f\"\\nEstimated returns calculated for {len(estimated_returns)} assets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5YTEwoarM2M"
      },
      "source": [
        "Save the estimated returns in a TSV file named \"estimated_returns.tsv\" and include a header row with the column names \"asset\" and \"estimated_return\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "At71YDpwvwUw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimated returns DataFrame:\n",
            "  asset  estimated_return\n",
            "0  AAPL          0.015442\n",
            "1   SPY          0.019666\n",
            "2  TSLA          0.025313\n",
            "3  MSFT          0.023318\n",
            "4     M          0.014757\n",
            "5   MCD          0.010268\n",
            "\n",
            "Estimated returns saved to: estimated_returns.tsv\n",
            "\n",
            "Summary:\n",
            "Number of assets: 6\n",
            "Highest expected return: 0.025313\n",
            "Lowest expected return: 0.010268\n",
            "Average expected return: 0.018127\n",
            "\n",
            "File verification: estimated_returns.tsv created successfully (102 bytes)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Create DataFrame with the required format\n",
        "estimated_returns_df = pd.DataFrame([\n",
        "    {'asset': asset, 'estimated_return': return_value}\n",
        "    for asset, return_value in estimated_returns.items()\n",
        "])\n",
        "\n",
        "# Round to 6 decimal places for consistency\n",
        "estimated_returns_df['estimated_return'] = estimated_returns_df['estimated_return'].round(6)\n",
        "\n",
        "print(\"Estimated returns DataFrame:\")\n",
        "print(estimated_returns_df)\n",
        "\n",
        "# Save to TSV file\n",
        "output_file = \"estimated_returns.tsv\"\n",
        "estimated_returns_df.to_csv(output_file, sep='\\t', index=False)\n",
        "print(f\"\\nEstimated returns saved to: {output_file}\")\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"Number of assets: {len(estimated_returns_df)}\")\n",
        "print(f\"Highest expected return: {estimated_returns_df['estimated_return'].max():.6f}\")\n",
        "print(f\"Lowest expected return: {estimated_returns_df['estimated_return'].min():.6f}\")\n",
        "print(f\"Average expected return: {estimated_returns_df['estimated_return'].mean():.6f}\")\n",
        "\n",
        "# File verification\n",
        "if os.path.exists(output_file):\n",
        "    file_size = os.path.getsize(output_file)\n",
        "    print(f\"\\nFile verification: {output_file} created successfully ({file_size} bytes)\")\n",
        "else:\n",
        "    print(f\"\\nERROR: {output_file} was not created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjfnF-2Wtj6r"
      },
      "source": [
        "Submit \"estimated_returns.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTuIqrkAWXVL"
      },
      "source": [
        "## Part 4: Estimate Risk\n",
        "\n",
        "Estimate the covariance matrix for the asset returns to understand how the assets move together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RFZfIkTMxcv7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Returns data loaded:\n",
            "Shape: (23, 7)\n",
            "Calculating covariance matrix for: ['AAPL', 'SPY', 'TSLA', 'MSFT', 'M', 'MCD']\n",
            "\n",
            "Covariance matrix calculated:\n",
            "Shape: (6, 6)\n",
            "\n",
            "Covariance Matrix:\n",
            "          AAPL       SPY      TSLA      MSFT         M       MCD\n",
            "AAPL  0.003627  0.000833  0.003255  0.000389  0.002522  0.000600\n",
            "SPY   0.000833  0.001292  0.002421  0.001488  0.002282  0.000123\n",
            "TSLA  0.003255  0.002421  0.026703  0.002217  0.004953  0.001064\n",
            "MSFT  0.000389  0.001488  0.002217  0.004044  0.002832 -0.000369\n",
            "M     0.002522  0.002282  0.004953  0.002832  0.012837  0.000655\n",
            "MCD   0.000600  0.000123  0.001064 -0.000369  0.000655  0.001819\n",
            "\n",
            "Correlation Matrix (for reference):\n",
            "          AAPL       SPY      TSLA      MSFT         M       MCD\n",
            "AAPL  1.000000  0.384539  0.330787  0.101593  0.369599  0.233454\n",
            "SPY   0.384539  1.000000  0.412117  0.650721  0.560266  0.080273\n",
            "TSLA  0.330787  0.412117  1.000000  0.213353  0.267535  0.152634\n",
            "MSFT  0.101593  0.650721  0.213353  1.000000  0.393113 -0.136049\n",
            "M     0.369599  0.560266  0.267535  0.393113  1.000000  0.135524\n",
            "MCD   0.233454  0.080273  0.152634 -0.136049  0.135524  1.000000\n",
            "\n",
            "Standard Deviations (Risk):\n",
            "AAPL: 0.060223\n",
            "SPY: 0.035950\n",
            "TSLA: 0.163412\n",
            "MSFT: 0.063592\n",
            "M: 0.113300\n",
            "MCD: 0.042644\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Read the returns data we created in Part 2\n",
        "returns_data = pd.read_csv(\"historical_returns.tsv\", sep='\\t')\n",
        "\n",
        "print(\"Returns data loaded:\")\n",
        "print(f\"Shape: {returns_data.shape}\")\n",
        "\n",
        "# Get all ticker columns (exclude the date column)\n",
        "tickers = [col for col in returns_data.columns if col != 'date']\n",
        "print(f\"Calculating covariance matrix for: {tickers}\")\n",
        "\n",
        "# Extract just the return columns for covariance calculation\n",
        "returns_only = returns_data[tickers]\n",
        "\n",
        "# Calculate the covariance matrix\n",
        "covariance_matrix = returns_only.cov()\n",
        "\n",
        "print(f\"\\nCovariance matrix calculated:\")\n",
        "print(f\"Shape: {covariance_matrix.shape}\")\n",
        "print(\"\\nCovariance Matrix:\")\n",
        "print(covariance_matrix)\n",
        "\n",
        "# Also calculate correlation matrix for reference (like in lecture notes)\n",
        "correlation_matrix = returns_only.corr()\n",
        "print(f\"\\nCorrelation Matrix (for reference):\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Calculate standard deviations for each asset (risk measure)\n",
        "std_devs = returns_only.std()\n",
        "print(f\"\\nStandard Deviations (Risk):\")\n",
        "for ticker in tickers:\n",
        "    print(f\"{ticker}: {std_devs[ticker]:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOmn4s_yr5qn"
      },
      "source": [
        "Save the estimated covariances to a TSV file named \"estimated_covariance.tsv\".\n",
        "The header row should have a blank column name followed by the names of the assets.\n",
        "Each data row should start with the name of an asset for that row, and be followed by the individual covariances corresponding to that row and column's assets.\n",
        "(This is the format of pandas's `to_csv` method with `sep=\"\\t\"` when used on a covariance matrix as computed in the examples.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Te-NPQxSvuXm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Covariance matrix saved to: estimated_covariance.tsv\n",
            "\n",
            "Saved covariance matrix format:\n",
            "          AAPL       SPY      TSLA      MSFT         M       MCD\n",
            "AAPL  0.003627  0.000833  0.003255  0.000389  0.002522  0.000600\n",
            "SPY   0.000833  0.001292  0.002421  0.001488  0.002282  0.000123\n",
            "TSLA  0.003255  0.002421  0.026703  0.002217  0.004953  0.001064\n",
            "MSFT  0.000389  0.001488  0.002217  0.004044  0.002832 -0.000369\n",
            "M     0.002522  0.002282  0.004953  0.002832  0.012837  0.000655\n",
            "MCD   0.000600  0.000123  0.001064 -0.000369  0.000655  0.001819\n",
            "\n",
            "File verification: estimated_covariance.tsv created successfully (836 bytes)\n",
            "\n",
            "Covariance Matrix Summary:\n",
            "Dimensions: 6x6\n",
            "Diagonal (variances):\n",
            "  AAPL: 0.003627 (std dev: 0.060223)\n",
            "  SPY: 0.001292 (std dev: 0.035950)\n",
            "  TSLA: 0.026703 (std dev: 0.163412)\n",
            "  MSFT: 0.004044 (std dev: 0.063592)\n",
            "  M: 0.012837 (std dev: 0.113300)\n",
            "  MCD: 0.001819 (std dev: 0.042644)\n",
            "\n",
            "Highest correlation: SPY & MSFT: 0.6507\n",
            "Lowest correlation: MSFT & MCD: -0.1360\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Saving the covariance matrix to TSV file\n",
        "# Using pandas to_csv with sep='\\t' as it automatically includes row names as first column\n",
        "output_file = \"estimated_covariance.tsv\"\n",
        "covariance_matrix.to_csv(output_file, sep='\\t')\n",
        "\n",
        "print(f\"Covariance matrix saved to: {output_file}\")\n",
        "\n",
        "# Display the saved format\n",
        "print(f\"\\nSaved covariance matrix format:\")\n",
        "saved_data = pd.read_csv(output_file, sep='\\t', index_col=0)\n",
        "print(saved_data)\n",
        "\n",
        "# File verification and summary\n",
        "if os.path.exists(output_file):\n",
        "    file_size = os.path.getsize(output_file)\n",
        "    print(f\"\\nFile verification: {output_file} created successfully ({file_size} bytes)\")\n",
        "else:\n",
        "    print(f\"\\nERROR: {output_file} was not created\")\n",
        "\n",
        "# Summary of covariance matrix properties\n",
        "print(f\"\\nCovariance Matrix Summary:\")\n",
        "print(f\"Dimensions: {covariance_matrix.shape[0]}x{covariance_matrix.shape[1]}\")\n",
        "print(f\"Diagonal (variances):\")\n",
        "for ticker in tickers:\n",
        "    variance = covariance_matrix.loc[ticker, ticker]\n",
        "    std_dev = np.sqrt(variance)\n",
        "    print(f\"  {ticker}: {variance:.6f} (std dev: {std_dev:.6f})\")\n",
        "\n",
        "# Find highest and lowest correlations (off-diagonal elements)\n",
        "corr_values = []\n",
        "for i in range(len(tickers)):\n",
        "    for j in range(i+1, len(tickers)):\n",
        "        corr_values.append((tickers[i], tickers[j], correlation_matrix.iloc[i,j]))\n",
        "\n",
        "corr_values.sort(key=lambda x: x[2])\n",
        "print(f\"\\nHighest correlation: {corr_values[-1][0]} & {corr_values[-1][1]}: {corr_values[-1][2]:.4f}\")\n",
        "print(f\"Lowest correlation: {corr_values[0][0]} & {corr_values[0][1]}: {corr_values[0][2]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS9vek0btoK6"
      },
      "source": [
        "Submit \"estimated_covariance.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8rC5Eo3sEme"
      },
      "source": [
        "## Part 5: Construct the Maximum Return Portfolio\n",
        "\n",
        "Compute the maximum return portfolio based on your previously estimated risks and returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8LW0KKm-xb2I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimated returns loaded:\n",
            "  asset  estimated_return\n",
            "0  AAPL          0.015442\n",
            "1   SPY          0.019666\n",
            "2  TSLA          0.025313\n",
            "3  MSFT          0.023318\n",
            "4     M          0.014757\n",
            "5   MCD          0.010268\n",
            "\n",
            "Asset with highest expected return:\n",
            "TSLA: 0.025313\n",
            "\n",
            "Maximum Return Portfolio:\n",
            "  asset  allocation\n",
            "0  AAPL         0.0\n",
            "1   SPY         0.0\n",
            "2  TSLA         1.0\n",
            "3  MSFT         0.0\n",
            "4     M         0.0\n",
            "5   MCD         0.0\n",
            "\n",
            "Constraint verification:\n",
            "Total allocation: 1.000000 (should be 1.0)\n",
            "All allocations non-negative: True\n",
            "Expected portfolio return: 0.025313\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Read the estimated returns we calculated in Part 3\n",
        "estimated_returns = pd.read_csv(\"estimated_returns.tsv\", sep='\\t')\n",
        "\n",
        "print(\"Estimated returns loaded:\")\n",
        "print(estimated_returns)\n",
        "\n",
        "# Find the asset with the highest expected return\n",
        "max_return_idx = estimated_returns['estimated_return'].idxmax()\n",
        "max_return_asset = estimated_returns.loc[max_return_idx, 'asset']\n",
        "max_return_value = estimated_returns.loc[max_return_idx, 'estimated_return']\n",
        "\n",
        "print(f\"\\nAsset with highest expected return:\")\n",
        "print(f\"{max_return_asset}: {max_return_value:.6f}\")\n",
        "\n",
        "# According to lecture notes, under standard investment constraints\n",
        "# (budget constraint: weights sum to 1, non-negativity: all weights >= 0)\n",
        "# the maximum return portfolio puts 100% in the highest return asset\n",
        "\n",
        "# Create maximum return portfolio\n",
        "max_return_portfolio = []\n",
        "for _, row in estimated_returns.iterrows():\n",
        "    asset = row['asset']\n",
        "    if asset == max_return_asset:\n",
        "        allocation = 1.0  # 100% allocation to highest return asset\n",
        "    else:\n",
        "        allocation = 0.0  # 0% allocation to all other assets\n",
        "    \n",
        "    max_return_portfolio.append({\n",
        "        'asset': asset,\n",
        "        'allocation': allocation\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "max_return_df = pd.DataFrame(max_return_portfolio)\n",
        "\n",
        "print(f\"\\nMaximum Return Portfolio:\")\n",
        "print(max_return_df)\n",
        "\n",
        "# Verify constraints\n",
        "total_allocation = max_return_df['allocation'].sum()\n",
        "all_non_negative = (max_return_df['allocation'] >= 0).all()\n",
        "\n",
        "print(f\"\\nConstraint verification:\")\n",
        "print(f\"Total allocation: {total_allocation:.6f} (should be 1.0)\")\n",
        "print(f\"All allocations non-negative: {all_non_negative}\")\n",
        "\n",
        "# Calculate expected portfolio return\n",
        "# Create a dictionary for easier lookup\n",
        "returns_dict = dict(zip(estimated_returns['asset'], estimated_returns['estimated_return']))\n",
        "\n",
        "# Calculate portfolio return: sum of (weight * return) for each asset\n",
        "portfolio_return = sum(max_return_df['allocation'] * max_return_df['asset'].map(returns_dict))\n",
        "print(f\"Expected portfolio return: {portfolio_return:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjPOxui5sLTD"
      },
      "source": [
        "Save the maximum return portfolio in a TSV file named \"maximum_return.tsv\".\n",
        "The header row should have two columns, \"asset\" and \"allocation\".\n",
        "The allocation values should sum up to one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xLl_j8z1vtiT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum return portfolio saved to: maximum_return.tsv\n",
            "\n",
            "Saved portfolio format:\n",
            "  asset  allocation\n",
            "0  AAPL         0.0\n",
            "1   SPY         0.0\n",
            "2  TSLA         1.0\n",
            "3  MSFT         0.0\n",
            "4     M         0.0\n",
            "5   MCD         0.0\n",
            "\n",
            "File verification: maximum_return.tsv created successfully (66 bytes)\n",
            "\n",
            "Portfolio Summary:\n",
            "Strategy: Maximum return (100% in highest return asset)\n",
            "Selected asset: TSLA\n",
            "Expected monthly return: 0.025313 (2.5313%)\n",
            "Number of assets in portfolio: 1\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Save the maximum return portfolio to TSV file\n",
        "output_file = \"maximum_return.tsv\"\n",
        "max_return_df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "print(f\"Maximum return portfolio saved to: {output_file}\")\n",
        "\n",
        "# Display the saved format\n",
        "print(f\"\\nSaved portfolio format:\")\n",
        "saved_portfolio = pd.read_csv(output_file, sep='\\t')\n",
        "print(saved_portfolio)\n",
        "\n",
        "# File verification\n",
        "if os.path.exists(output_file):\n",
        "    file_size = os.path.getsize(output_file)\n",
        "    print(f\"\\nFile verification: {output_file} created successfully ({file_size} bytes)\")\n",
        "else:\n",
        "    print(f\"\\nERROR: {output_file} was not created\")\n",
        "\n",
        "# Portfolio summary\n",
        "print(f\"\\nPortfolio Summary:\")\n",
        "print(f\"Strategy: Maximum return (100% in highest return asset)\")\n",
        "print(f\"Selected asset: {max_return_asset}\")\n",
        "print(f\"Expected monthly return: {portfolio_return:.6f} ({portfolio_return*100:.4f}%)\")\n",
        "print(f\"Number of assets in portfolio: {(max_return_df['allocation'] > 0).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bm3xrxptqJ2"
      },
      "source": [
        "Submit \"maximum_return.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_QxQ5NpsL-c"
      },
      "source": [
        "## Part 6: Construct the Minimum Risk Portfolio\n",
        "\n",
        "Compute the minimum risk portfolio based on your previously estimated risks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "daHSqhv9xbIF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Covariance matrix loaded:\n",
            "          AAPL       SPY      TSLA      MSFT         M       MCD\n",
            "AAPL  0.003627  0.000833  0.003255  0.000389  0.002522  0.000600\n",
            "SPY   0.000833  0.001292  0.002421  0.001488  0.002282  0.000123\n",
            "TSLA  0.003255  0.002421  0.026703  0.002217  0.004953  0.001064\n",
            "MSFT  0.000389  0.001488  0.002217  0.004044  0.002832 -0.000369\n",
            "M     0.002522  0.002282  0.004953  0.002832  0.012837  0.000655\n",
            "MCD   0.000600  0.000123  0.001064 -0.000369  0.000655  0.001819\n",
            "\n",
            "Assets: ['AAPL', 'SPY', 'TSLA', 'MSFT', 'M', 'MCD']\n",
            "Number of assets: 6\n",
            "\n",
            "Covariance matrix shape: (6, 6)\n",
            "\n",
            "Initial weights (equal allocation): [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
            "Initial portfolio variance: 0.002801\n",
            "\n",
            "Optimization result:\n",
            "Success: True\n",
            "Minimum variance: 0.000842\n",
            "Minimum standard deviation (risk): 0.029022\n",
            "\n",
            "Minimum Risk Portfolio:\n",
            "  asset    allocation\n",
            "0  AAPL  9.445829e-02\n",
            "1   SPY  3.133991e-01\n",
            "2  TSLA  2.255141e-17\n",
            "3  MSFT  1.143472e-01\n",
            "4     M  0.000000e+00\n",
            "5   MCD  4.777954e-01\n",
            "\n",
            "Constraint verification:\n",
            "Total allocation: 1.000000 (should be 1.0)\n",
            "All allocations non-negative: True\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Load the covariance matrix from Part 4\n",
        "covariance_matrix = pd.read_csv(\"estimated_covariance.tsv\", sep='\\t', index_col=0)\n",
        "\n",
        "print(\"Covariance matrix loaded:\")\n",
        "print(covariance_matrix)\n",
        "\n",
        "# Get asset names\n",
        "assets = list(covariance_matrix.columns)\n",
        "n_assets = len(assets)\n",
        "\n",
        "print(f\"\\nAssets: {assets}\")\n",
        "print(f\"Number of assets: {n_assets}\")\n",
        "\n",
        "# Convert covariance matrix to numpy array for optimization\n",
        "cov_array = covariance_matrix.values\n",
        "\n",
        "print(f\"\\nCovariance matrix shape: {cov_array.shape}\")\n",
        "\n",
        "# Define the objective function: minimize portfolio variance\n",
        "# Portfolio variance = w^T * Σ * w (where w is weights, Σ is covariance matrix)\n",
        "def portfolio_variance(weights, cov_matrix):\n",
        "    return np.dot(weights.T, np.dot(cov_matrix, weights))\n",
        "\n",
        "# Define constraints\n",
        "# Budget constraint: sum of weights = 1\n",
        "constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]\n",
        "\n",
        "# Non-negativity constraints: all weights >= 0\n",
        "bounds = [(0, 1) for _ in range(n_assets)]\n",
        "\n",
        "# Initial guess: equal weights\n",
        "initial_weights = np.array([1/n_assets] * n_assets)\n",
        "\n",
        "print(f\"\\nInitial weights (equal allocation): {initial_weights}\")\n",
        "print(f\"Initial portfolio variance: {portfolio_variance(initial_weights, cov_array):.6f}\")\n",
        "\n",
        "# Solve the optimization problem\n",
        "result = minimize(\n",
        "    portfolio_variance,\n",
        "    initial_weights,\n",
        "    args=(cov_array,),\n",
        "    method='SLSQP',\n",
        "    bounds=bounds,\n",
        "    constraints=constraints\n",
        ")\n",
        "\n",
        "# Extract optimal weights\n",
        "optimal_weights = result.x\n",
        "min_variance = result.fun\n",
        "\n",
        "print(f\"\\nOptimization result:\")\n",
        "print(f\"Success: {result.success}\")\n",
        "print(f\"Minimum variance: {min_variance:.6f}\")\n",
        "print(f\"Minimum standard deviation (risk): {np.sqrt(min_variance):.6f}\")\n",
        "\n",
        "# Create minimum risk portfolio DataFrame\n",
        "min_risk_portfolio = pd.DataFrame({\n",
        "    'asset': assets,\n",
        "    'allocation': optimal_weights\n",
        "})\n",
        "\n",
        "print(f\"\\nMinimum Risk Portfolio:\")\n",
        "print(min_risk_portfolio)\n",
        "\n",
        "# Verify constraints\n",
        "total_allocation = min_risk_portfolio['allocation'].sum()\n",
        "all_non_negative = (min_risk_portfolio['allocation'] >= 0).all()\n",
        "\n",
        "print(f\"\\nConstraint verification:\")\n",
        "print(f\"Total allocation: {total_allocation:.6f} (should be 1.0)\")\n",
        "print(f\"All allocations non-negative: {all_non_negative}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzldkIPxsQor"
      },
      "source": [
        "Save the minimum risk portfolio in a TSV file named \"minimum_risk.tsv\".\n",
        "The header row should have two columns, \"asset\" and \"allocation\".\n",
        "The allocation values should sum up to one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "YRXccAflvrBZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum risk portfolio saved to: minimum_risk.tsv\n",
            "\n",
            "Saved portfolio format:\n",
            "  asset  allocation\n",
            "0  AAPL    0.094458\n",
            "1   SPY    0.313399\n",
            "2  TSLA    0.000000\n",
            "3  MSFT    0.114347\n",
            "4     M    0.000000\n",
            "5   MCD    0.477795\n",
            "\n",
            "File verification: minimum_risk.tsv created successfully (86 bytes)\n",
            "\n",
            "Portfolio Summary:\n",
            "Strategy: Minimum risk (variance minimization)\n",
            "Portfolio variance: 0.000842\n",
            "Portfolio standard deviation: 0.029022\n",
            "Expected portfolio return: 0.015194 (1.5194%)\n",
            "Number of assets with positive allocation: 4\n",
            "\n",
            "Assets with allocation > 0.1%:\n",
            "  AAPL: 0.0945 (9.45%)\n",
            "  SPY: 0.3134 (31.34%)\n",
            "  MSFT: 0.1143 (11.43%)\n",
            "  MCD: 0.4778 (47.78%)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Round allocations\n",
        "min_risk_portfolio['allocation'] = min_risk_portfolio['allocation'].round(6)\n",
        "\n",
        "# Save the minimum risk portfolio to TSV file\n",
        "output_file = \"minimum_risk.tsv\"\n",
        "min_risk_portfolio.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "print(f\"Minimum risk portfolio saved to: {output_file}\")\n",
        "\n",
        "# Display the saved format\n",
        "print(f\"\\nSaved portfolio format:\")\n",
        "saved_portfolio = pd.read_csv(output_file, sep='\\t')\n",
        "print(saved_portfolio)\n",
        "\n",
        "# File verification\n",
        "if os.path.exists(output_file):\n",
        "    file_size = os.path.getsize(output_file)\n",
        "    print(f\"\\nFile verification: {output_file} created successfully ({file_size} bytes)\")\n",
        "else:\n",
        "    print(f\"\\nERROR: {output_file} was not created\")\n",
        "\n",
        "# Calculate expected return of minimum risk portfolio\n",
        "estimated_returns = pd.read_csv(\"estimated_returns.tsv\", sep='\\t')\n",
        "returns_dict = dict(zip(estimated_returns['asset'], estimated_returns['estimated_return']))\n",
        "\n",
        "portfolio_return = sum(min_risk_portfolio['allocation'] * min_risk_portfolio['asset'].map(returns_dict))\n",
        "\n",
        "print(f\"\\nPortfolio Summary:\")\n",
        "print(f\"Strategy: Minimum risk (variance minimization)\")\n",
        "print(f\"Portfolio variance: {min_variance:.6f}\")\n",
        "print(f\"Portfolio standard deviation: {np.sqrt(min_variance):.6f}\")\n",
        "print(f\"Expected portfolio return: {portfolio_return:.6f} ({portfolio_return*100:.4f}%)\")\n",
        "print(f\"Number of assets with positive allocation: {(min_risk_portfolio['allocation'] > 0.001).sum()}\")\n",
        "\n",
        "# Show which assets have meaningful allocations\n",
        "print(f\"\\nAssets with allocation > 0.1%:\")\n",
        "for _, row in min_risk_portfolio.iterrows():\n",
        "    if row['allocation'] > 0.001:\n",
        "        print(f\"  {row['asset']}: {row['allocation']:.4f} ({row['allocation']*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5gy_XETtsoi"
      },
      "source": [
        "Submit \"minimum_risk.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzyJGWDvWhva"
      },
      "source": [
        "## Part 7: Build Efficient Frontier Portfolios\n",
        "\n",
        "Compute 101 portfolios along the mean-variance efficient frontier with evenly spaced estimated returns.\n",
        "The first portfolio should be the minimum risk portfolio from part 4, and the last portfolio should be the maximum return portfolio from part 3.\n",
        "The estimated return of each portfolio should be higher than the previous by one percent of the difference between the first and last portfolios.\n",
        "That is, the estimated return of the portfolios should be similar to `np.linspace(min_risk_return, max_return, 101)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "XaR6mKwvxZ4W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All dfs loaded\n",
            "Assets: ['AAPL', 'SPY', 'TSLA', 'MSFT', 'M', 'MCD']\n",
            "Number of assets: 6\n",
            "\n",
            "Minimum risk portfolio return: 0.015194\n",
            "Maximum return portfolio return: 0.025313\n",
            "\n",
            "Target returns range: 0.015194 to 0.025313\n",
            "Number of portfolios: 101\n",
            "Portfolio 0: Return=0.015194, Risk=0.028677\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Portfolio 20: Return=0.017218, Risk=0.029441\n",
            "Portfolio 40: Return=0.019242, Risk=0.034164\n",
            "Portfolio 60: Return=0.021266, Risk=0.043433\n",
            "Portfolio 80: Return=0.023289, Risk=0.060537\n",
            "Portfolio 100: Return=0.025313, Risk=0.163412\n",
            "\n",
            "Optimized 101 portfolios\n",
            "\n",
            "Efficient frontier DataFrame shape: (101, 9)\n",
            "First few portfolios:\n",
            "   index    return      risk      AAPL       SPY          TSLA      MSFT  \\\n",
            "0      0  0.015194  0.028677  0.039058  0.456790  0.000000e+00  0.033047   \n",
            "1      1  0.015295  0.028610  0.038079  0.465558  1.734723e-18  0.034875   \n",
            "2      2  0.015397  0.028553  0.037099  0.474326  0.000000e+00  0.036703   \n",
            "3      3  0.015498  0.028508  0.036120  0.483094  0.000000e+00  0.038531   \n",
            "4      4  0.015599  0.028474  0.035218  0.491947  2.328324e-17  0.040266   \n",
            "\n",
            "              M       MCD  \n",
            "0  1.680513e-18  0.471104  \n",
            "1  4.336809e-18  0.461488  \n",
            "2  3.035766e-18  0.451872  \n",
            "3  0.000000e+00  0.442255  \n",
            "4  0.000000e+00  0.432568  \n",
            "\n",
            "Last few portfolios:\n",
            "     index    return      risk          AAPL           SPY      TSLA  \\\n",
            "96      96  0.024908  0.133607  7.158987e-18  7.979728e-17  0.797118   \n",
            "97      97  0.025009  0.140929  2.236375e-17  0.000000e+00  0.847839   \n",
            "98      98  0.025111  0.148345  2.473300e-17  0.000000e+00  0.898559   \n",
            "99      99  0.025212  0.155843  0.000000e+00  0.000000e+00  0.949280   \n",
            "100    100  0.025313  0.163412  0.000000e+00  0.000000e+00  1.000000   \n",
            "\n",
            "         MSFT             M           MCD  \n",
            "96   0.202882  2.051484e-18  0.000000e+00  \n",
            "97   0.152161  6.865436e-19  1.372125e-17  \n",
            "98   0.101441  0.000000e+00  3.735758e-17  \n",
            "99   0.050720  0.000000e+00  1.689762e-17  \n",
            "100  0.000000  0.000000e+00  0.000000e+00  \n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Load required data\n",
        "covariance_matrix = pd.read_csv(\"estimated_covariance.tsv\", sep='\\t', index_col=0)\n",
        "estimated_returns = pd.read_csv(\"estimated_returns.tsv\", sep='\\t')\n",
        "min_risk_portfolio = pd.read_csv(\"minimum_risk.tsv\", sep='\\t')\n",
        "max_return_portfolio = pd.read_csv(\"maximum_return.tsv\", sep='\\t')\n",
        "\n",
        "print(\"All dfs loaded\")\n",
        "\n",
        "# Get asset information\n",
        "assets = list(covariance_matrix.columns)\n",
        "n_assets = len(assets)\n",
        "cov_array = covariance_matrix.values\n",
        "\n",
        "# Create returns dictionary and array\n",
        "returns_dict = dict(zip(estimated_returns['asset'], estimated_returns['estimated_return']))\n",
        "returns_array = np.array([returns_dict[asset] for asset in assets])\n",
        "\n",
        "print(f\"Assets: {assets}\")\n",
        "print(f\"Number of assets: {n_assets}\")\n",
        "\n",
        "# Calculate min and max portfolio returns\n",
        "min_risk_return = sum(min_risk_portfolio['allocation'] * min_risk_portfolio['asset'].map(returns_dict))\n",
        "max_return_value = sum(max_return_portfolio['allocation'] * max_return_portfolio['asset'].map(returns_dict))\n",
        "\n",
        "print(f\"\\nMinimum risk portfolio return: {min_risk_return:.6f}\")\n",
        "print(f\"Maximum return portfolio return: {max_return_value:.6f}\")\n",
        "\n",
        "# Create 101 evenly spaced target returns\n",
        "target_returns = np.linspace(min_risk_return, max_return_value, 101)\n",
        "print(f\"\\nTarget returns range: {target_returns[0]:.6f} to {target_returns[-1]:.6f}\")\n",
        "print(f\"Number of portfolios: {len(target_returns)}\")\n",
        "\n",
        "# Define portfolio optimization functions\n",
        "def portfolio_variance(weights, cov_matrix):\n",
        "    return np.dot(weights.T, np.dot(cov_matrix, weights))\n",
        "\n",
        "def portfolio_return(weights, returns):\n",
        "    return np.dot(weights, returns)\n",
        "\n",
        "# Store results\n",
        "efficient_portfolios = []\n",
        "\n",
        "for i, target_return in enumerate(target_returns):\n",
        "    # Define constraints\n",
        "    constraints = [\n",
        "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},  # Budget constraint\n",
        "        {'type': 'eq', 'fun': lambda w, ret=target_return: portfolio_return(w, returns_array) - ret}  # Return constraint\n",
        "    ]\n",
        "    \n",
        "    # Bounds for non-negativity\n",
        "    bounds = [(0, 1) for _ in range(n_assets)]\n",
        "    \n",
        "    # Initial guess - use min risk portfolio for first, adjust for others\n",
        "    if i == 0:\n",
        "        initial_weights = min_risk_portfolio['allocation'].values\n",
        "    elif i == len(target_returns) - 1:\n",
        "        initial_weights = max_return_portfolio['allocation'].values\n",
        "    else:\n",
        "        # Linear interpolation between min risk and max return portfolios\n",
        "        alpha = i / (len(target_returns) - 1)\n",
        "        initial_weights = ((1 - alpha) * min_risk_portfolio['allocation'].values + \n",
        "                          alpha * max_return_portfolio['allocation'].values)\n",
        "    \n",
        "    # Solve optimization\n",
        "    result = minimize(\n",
        "        portfolio_variance,\n",
        "        initial_weights,\n",
        "        args=(cov_array,),\n",
        "        method='SLSQP',\n",
        "        bounds=bounds,\n",
        "        constraints=constraints,\n",
        "        options={'ftol': 1e-9, 'maxiter': 1000}\n",
        "    )\n",
        "    \n",
        "    if result.success:\n",
        "        weights = result.x\n",
        "        portfolio_var = result.fun\n",
        "        portfolio_std = np.sqrt(portfolio_var)\n",
        "        actual_return = portfolio_return(weights, returns_array)\n",
        "        \n",
        "        # Store portfolio information\n",
        "        portfolio_data = {\n",
        "            'index': i,\n",
        "            'return': actual_return,\n",
        "            'risk': portfolio_std\n",
        "        }\n",
        "        \n",
        "        # Add asset allocations\n",
        "        for j, asset in enumerate(assets):\n",
        "            portfolio_data[asset] = weights[j]\n",
        "        \n",
        "        efficient_portfolios.append(portfolio_data)\n",
        "        \n",
        "        if i % 20 == 0:  # Progress update every 20 portfolios\n",
        "            print(f\"Portfolio {i}: Return={actual_return:.6f}, Risk={portfolio_std:.6f}\")\n",
        "    \n",
        "    else:\n",
        "        print(f\"Optimization failed for portfolio {i} with target return {target_return:.6f}\")\n",
        "\n",
        "print(f\"\\nOptimized {len(efficient_portfolios)} portfolios\")\n",
        "\n",
        "# Create DataFrame\n",
        "efficient_frontier_df = pd.DataFrame(efficient_portfolios)\n",
        "\n",
        "print(f\"\\nEfficient frontier DataFrame shape: {efficient_frontier_df.shape}\")\n",
        "print(\"First few portfolios:\")\n",
        "print(efficient_frontier_df.head())\n",
        "print(\"\\nLast few portfolios:\")\n",
        "print(efficient_frontier_df.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e3WwTJvsDzh"
      },
      "source": [
        "Save the portfolios in a TSV file named \"efficient_frontier.tsv\".\n",
        "The header row should have columns \"index\", \"return\", \"risk\", and all the asset tickers.\n",
        "Each data row should have the portfolio index (0-100), the estimated return of the portfolio, the estimated standard deviation (not variance) of the portfolio, and all the asset allocations (which should sum to one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "e9DKadyNvniT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Allocation verification:\n",
            "Min sum: 0.999999\n",
            "Max sum: 1.000001\n",
            "All sums close to 1.0: True\n",
            "\n",
            "Efficient frontier saved to: efficient_frontier.tsv\n",
            "File verification: efficient_frontier.tsv created successfully (6108 bytes)\n",
            "\n",
            "Efficient Frontier Summary:\n",
            "Number of portfolios: 101\n",
            "Return range: 0.015194 to 0.025313\n",
            "Risk range: 0.028439 to 0.163412\n",
            "\n",
            "First portfolio (minimum risk):\n",
            "Return: 0.015194, Risk: 0.028677\n",
            "  AAPL: 0.0391\n",
            "  SPY: 0.4568\n",
            "  MSFT: 0.0330\n",
            "  MCD: 0.4711\n",
            "\n",
            "Last portfolio (maximum return):\n",
            "Return: 0.025313, Risk: 0.163412\n",
            "  TSLA: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Round values for cleaner output\n",
        "efficient_frontier_df['return'] = efficient_frontier_df['return'].round(6)\n",
        "efficient_frontier_df['risk'] = efficient_frontier_df['risk'].round(6)\n",
        "\n",
        "# Round asset allocations\n",
        "for asset in assets:\n",
        "    efficient_frontier_df[asset] = efficient_frontier_df[asset].round(6)\n",
        "\n",
        "# Verify allocations sum to 1\n",
        "allocation_sums = efficient_frontier_df[assets].sum(axis=1)\n",
        "print(f\"\\nAllocation verification:\")\n",
        "print(f\"Min sum: {allocation_sums.min():.6f}\")\n",
        "print(f\"Max sum: {allocation_sums.max():.6f}\")\n",
        "print(f\"All sums close to 1.0: {np.allclose(allocation_sums, 1.0, atol=1e-5)}\")\n",
        "\n",
        "# Save to TSV file\n",
        "output_file = \"efficient_frontier.tsv\"\n",
        "efficient_frontier_df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "print(f\"\\nEfficient frontier saved to: {output_file}\")\n",
        "\n",
        "# File verification\n",
        "if os.path.exists(output_file):\n",
        "    file_size = os.path.getsize(output_file)\n",
        "    print(f\"File verification: {output_file} created successfully ({file_size} bytes)\")\n",
        "else:\n",
        "    print(f\"ERROR: {output_file} was not created\")\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\nEfficient Frontier Summary:\")\n",
        "print(f\"Number of portfolios: {len(efficient_frontier_df)}\")\n",
        "print(f\"Return range: {efficient_frontier_df['return'].min():.6f} to {efficient_frontier_df['return'].max():.6f}\")\n",
        "print(f\"Risk range: {efficient_frontier_df['risk'].min():.6f} to {efficient_frontier_df['risk'].max():.6f}\")\n",
        "\n",
        "# Show first portfolio (minimum risk)\n",
        "print(f\"\\nFirst portfolio (minimum risk):\")\n",
        "first_portfolio = efficient_frontier_df.iloc[0]\n",
        "print(f\"Return: {first_portfolio['return']:.6f}, Risk: {first_portfolio['risk']:.6f}\")\n",
        "for asset in assets:\n",
        "    if first_portfolio[asset] > 0.001:\n",
        "        print(f\"  {asset}: {first_portfolio[asset]:.4f}\")\n",
        "\n",
        "# Show last portfolio (maximum return)\n",
        "print(f\"\\nLast portfolio (maximum return):\")\n",
        "last_portfolio = efficient_frontier_df.iloc[-1]\n",
        "print(f\"Return: {last_portfolio['return']:.6f}, Risk: {last_portfolio['risk']:.6f}\")\n",
        "for asset in assets:\n",
        "    if last_portfolio[asset] > 0.001:\n",
        "        print(f\"  {asset}: {last_portfolio[asset]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiOa06rItvbs"
      },
      "source": [
        "Submit \"efficient_frontier.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoW0XBXAzzR6"
      },
      "source": [
        "## Part 8: Check Maximum Return Portfolio Stability\n",
        "\n",
        "Check the stability of the maximum return portfolio by resampling the estimated risk/return model.\n",
        "\n",
        "Repeat 1000 times -\n",
        "1. Use `np.random.multivariate_normal` to generate 23 return samples using your previously estimated risks and returns.\n",
        "2. Estimate the return of each asset using that resampled return history.\n",
        "3. Check which asset had the highest return in those resampled estimates.\n",
        "\n",
        "This procedure is a reduced and simplified version of the Michaud resampled efficient frontier procedure that takes uncertainty in the risk model into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Xfke5V57xYvT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded for stability analysis\n",
            "Assets: ['AAPL', 'SPY', 'TSLA', 'MSFT', 'M', 'MCD']\n",
            "Running 1000 simulations with 23 samples each\n",
            "\n",
            "Original estimated returns:\n",
            "  AAPL: 0.015442\n",
            "  SPY: 0.019666\n",
            "  TSLA: 0.025313\n",
            "  MSFT: 0.023318\n",
            "  M: 0.014757\n",
            "  MCD: 0.010268\n",
            "Completed 200 simulations\n",
            "Completed 400 simulations\n",
            "Completed 600 simulations\n",
            "Completed 800 simulations\n",
            "Completed 1000 simulations\n",
            "\n",
            "Simulation results:\n",
            "Times each asset had the highest return:\n",
            "  AAPL: 75 times (0.075 probability)\n",
            "  SPY: 47 times (0.047 probability)\n",
            "  TSLA: 418 times (0.418 probability)\n",
            "  MSFT: 269 times (0.269 probability)\n",
            "  M: 148 times (0.148 probability)\n",
            "  MCD: 43 times (0.043 probability)\n",
            "\n",
            "Stability Results (sorted by probability):\n",
            "  asset  probability\n",
            "2  TSLA        0.418\n",
            "3  MSFT        0.269\n",
            "4     M        0.148\n",
            "0  AAPL        0.075\n",
            "1   SPY        0.047\n",
            "5   MCD        0.043\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Load required data\n",
        "estimated_returns = pd.read_csv(\"estimated_returns.tsv\", sep='\\t')\n",
        "covariance_matrix = pd.read_csv(\"estimated_covariance.tsv\", sep='\\t', index_col=0)\n",
        "\n",
        "print(\"Data loaded for stability analysis\")\n",
        "\n",
        "# Get assets and setup parameters\n",
        "assets = list(covariance_matrix.columns)\n",
        "n_assets = len(assets)\n",
        "n_samples = 23  # Number of return observations we had\n",
        "n_simulations = 1000\n",
        "\n",
        "print(f\"Assets: {assets}\")\n",
        "print(f\"Running {n_simulations} simulations with {n_samples} samples each\")\n",
        "\n",
        "# Create mean returns vector and covariance matrix as numpy arrays\n",
        "mean_returns = np.array([estimated_returns[estimated_returns['asset'] == asset]['estimated_return'].iloc[0] \n",
        "                        for asset in assets])\n",
        "cov_matrix = covariance_matrix.values\n",
        "\n",
        "print(f\"\\nOriginal estimated returns:\")\n",
        "for i, asset in enumerate(assets):\n",
        "    print(f\"  {asset}: {mean_returns[i]:.6f}\")\n",
        "\n",
        "# Track which asset has highest return in each simulation\n",
        "highest_return_counts = {asset: 0 for asset in assets}\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "for sim in range(n_simulations):\n",
        "    # Generate 23 random return samples using multivariate normal distribution\n",
        "    # Each row is a time period, each column is an asset\n",
        "    simulated_returns = np.random.multivariate_normal(mean_returns, cov_matrix, n_samples)\n",
        "    \n",
        "    # Calculate mean return for each asset from the simulated data\n",
        "    resampled_means = np.mean(simulated_returns, axis=0)\n",
        "    \n",
        "    # Find which asset has the highest resampled mean return\n",
        "    highest_return_idx = np.argmax(resampled_means)\n",
        "    highest_return_asset = assets[highest_return_idx]\n",
        "    \n",
        "    # Increment counter for this asset\n",
        "    highest_return_counts[highest_return_asset] += 1\n",
        "    \n",
        "    # Progress update every 200 simulations\n",
        "    if (sim + 1) % 200 == 0:\n",
        "        print(f\"Completed {sim + 1} simulations\")\n",
        "\n",
        "print(f\"\\nSimulation results:\")\n",
        "print(f\"Times each asset had the highest return:\")\n",
        "for asset in assets:\n",
        "    count = highest_return_counts[asset]\n",
        "    probability = count / n_simulations\n",
        "    print(f\"  {asset}: {count} times ({probability:.3f} probability)\")\n",
        "\n",
        "# Calculate probabilities\n",
        "probabilities = []\n",
        "for asset in assets:\n",
        "    prob = highest_return_counts[asset] / n_simulations\n",
        "    probabilities.append({'asset': asset, 'probability': prob})\n",
        "\n",
        "# Create results DataFrame\n",
        "stability_results = pd.DataFrame(probabilities)\n",
        "stability_results = stability_results.sort_values('probability', ascending=False)\n",
        "\n",
        "print(f\"\\nStability Results (sorted by probability):\")\n",
        "print(stability_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fes_ScDyz0jp"
      },
      "source": [
        "Save a file \"max_return_probabilities.tsv\" with the distribution of highest return assets.\n",
        "The header row should have columns \"asset\" and \"probability\".\n",
        "There should be a data row for each asset and its sample probability of having the highest return based on those 1000 resampled estimates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ZAjr15ASvj1S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Maximum return probabilities saved to: max_return_probabilities.tsv\n",
            "\n",
            "Saved probabilities:\n",
            "  asset  probability\n",
            "0  TSLA        0.418\n",
            "1  MSFT        0.269\n",
            "2     M        0.148\n",
            "3  AAPL        0.075\n",
            "4   SPY        0.047\n",
            "5   MCD        0.043\n",
            "\n",
            "File verification: max_return_probabilities.tsv created successfully (79 bytes)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Round probabilities to reasonable precision\n",
        "stability_results['probability'] = stability_results['probability'].round(4)\n",
        "\n",
        "# Save to TSV file\n",
        "output_file = \"max_return_probabilities.tsv\"\n",
        "stability_results.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "print(f\"\\nMaximum return probabilities saved to: {output_file}\")\n",
        "\n",
        "# Display the saved format\n",
        "print(f\"\\nSaved probabilities:\")\n",
        "saved_data = pd.read_csv(output_file, sep='\\t')\n",
        "print(saved_data)\n",
        "\n",
        "# File verification\n",
        "if os.path.exists(output_file):\n",
        "    file_size = os.path.getsize(output_file)\n",
        "    print(f\"\\nFile verification: {output_file} created successfully ({file_size} bytes)\")\n",
        "else:\n",
        "    print(f\"\\nERROR: {output_file} was not created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xd34FQ6txoj"
      },
      "source": [
        "Submit \"max_return_probabilities.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYbJ21qUYvL_"
      },
      "source": [
        "## Part 9: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3oWYYHlt42V"
      },
      "source": [
        "Submit \"acknowledgements.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8FWiTjvwscA"
      },
      "source": [
        "## Part 10: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDEYI-K8vcUW"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
